package transpiler

import (
	"encoding/json"
	"jsson/internal/ast"
	ie "jsson/internal/errors"
	"jsson/internal/lexer"
	"jsson/internal/parser"
	"os"
	"path/filepath"
)

// RangeResult wraps a slice generated by a range expression
// This allows ArrayLiteral to distinguish between a range (to be flattened) and a nested array
type RangeResult struct {
	Values []interface{}
}

// Transpiler converts JSSON AST to JSON/YAML/TOML/TypeScript
type Transpiler struct {
	program *ast.Program
	baseDir string
	// includeCache stores previously transpiled include outputs keyed by absolute path
	includeCache map[string]map[string]interface{}
	// inProgress marks includes currently being processed to detect cycles
	inProgress map[string]bool
	// mergeMode controls include merge behavior: "keep" (default), "overwrite", "error"
	mergeMode string
	// sourceFile is the path to the source file being transpiled (optional)
	sourceFile string
	// symbolTable stores variable declarations (name := value)
	symbolTable map[string]interface{}
	// presetTable stores preset definitions (@preset "name" { ... })
	presetTable map[string]*ast.ObjectLiteral
	// Streaming support
	streamingEnabled bool
	streamThreshold  int64 // Auto-enable streaming if range size > threshold
}

// New creates a new Transpiler instance
func New(program *ast.Program, baseDir string, mergeMode string, sourceFile string) *Transpiler {
	if mergeMode == "" {
		mergeMode = "keep"
	}
	return &Transpiler{
		program:          program,
		baseDir:          baseDir,
		includeCache:     make(map[string]map[string]interface{}),
		inProgress:       make(map[string]bool),
		mergeMode:        mergeMode,
		sourceFile:       sourceFile,
		symbolTable:      make(map[string]interface{}),
		presetTable:      make(map[string]*ast.ObjectLiteral),
		streamingEnabled: false,
		streamThreshold:  10000, // Default: auto-enable streaming for ranges > 10k items
	}
}

// Transpile converts the JSSON program to JSON bytes
func (t *Transpiler) Transpile() ([]byte, error) {
	root := make(map[string]interface{})

	for _, stmt := range t.program.Statements {
		switch s := stmt.(type) {
		case *ast.PresetStatement:
			// Preset definitions are stored in preset table but not added to output
			t.presetTable[s.Name.Value] = s.Body
		case *ast.VariableDeclaration:
			// Variable declarations are stored in symbol table but not added to output
			val, err := t.evalExpression(s.Value, nil)
			if err != nil {
				return nil, err
			}
			t.symbolTable[s.Name.Value] = val
		case *ast.AssignmentStatement:
			key := s.Name.Value
			val, err := t.evalExpression(s.Value, nil)
			if err != nil {
				return nil, err
			}
			// Store in symbol table so it can be referenced by other expressions
			t.symbolTable[key] = val
			// Also add to output
			root[key] = val
		case *ast.IncludeStatement:
			if err := t.processInclude(s, root); err != nil {
				return nil, err
			}
		}
	}

	// Convert any RangeResult to plain slices before JSON marshaling
	root = t.convertRangeResults(root).(map[string]interface{})

	return json.MarshalIndent(root, "", "  ")
}

// processInclude handles include statements
func (t *Transpiler) processInclude(s *ast.IncludeStatement, root map[string]interface{}) error {
	includePath := s.Path.Value

	// Resolve path relative to the current Transpiler baseDir when not absolute
	var includeAbs string
	if filepath.IsAbs(includePath) {
		includeAbs = filepath.Clean(includePath)
	} else {
		includeAbs = filepath.Clean(filepath.Join(t.baseDir, includePath))
	}

	// Detect cyclic include
	if t.inProgress[includeAbs] {
		return t.errfNodeMsg(s, ie.CyclicInclude(includeAbs))
	}

	// If cached, use cached result
	if cached, ok := t.includeCache[includeAbs]; ok {
		for k, v := range cached {
			if _, exists := root[k]; !exists {
				root[k] = v
			}
		}
		return nil
	}

	// Mark as in-progress
	t.inProgress[includeAbs] = true

	data, err := os.ReadFile(includeAbs)
	if err != nil {
		t.inProgress[includeAbs] = false
		return t.errfNode(s, "could not read include file %q — gremlin can't find it: %v", s.Path.Value, err)
	}

	l := lexer.New(string(data))
	l.SetSourceFile(includeAbs)
	p := parser.New(l)
	prog := p.ParseProgram()
	if len(p.Errors()) > 0 {
		t.inProgress[includeAbs] = false
		return t.errfNode(s, "parser errors in included file %q — wizard got confused: %v", s.Path.Value, p.Errors())
	}

	// Create a transpiler for the included program, setting its baseDir to the included file's dir
	incBase := filepath.Dir(includeAbs)
	incT := New(prog, incBase, t.mergeMode, includeAbs)
	// share cache and inProgress maps so nested includes use the same state
	incT.includeCache = t.includeCache
	incT.inProgress = t.inProgress

	incJSON, err := incT.Transpile()
	if err != nil {
		t.inProgress[includeAbs] = false
		return t.errfNode(s, "transpile error in included file %q: %v", s.Path.Value, err)
	}

	var incRoot map[string]interface{}
	if err := json.Unmarshal(incJSON, &incRoot); err != nil {
		t.inProgress[includeAbs] = false
		return t.errfNode(s, "invalid json from include %q: %v", s.Path.Value, err)
	}

	// Cache result
	t.includeCache[includeAbs] = incRoot
	// Done processing
	t.inProgress[includeAbs] = false

	// Merge according to mergeMode
	for k, v := range incRoot {
		switch t.mergeMode {
		case "keep":
			if _, exists := root[k]; !exists {
				root[k] = v
			}
		case "overwrite":
			root[k] = v
		case "error":
			if _, exists := root[k]; exists {
				return t.errfNode(s, "include merge conflict for key %q from %s", k, includeAbs)
			}
			root[k] = v
		default:
			if _, exists := root[k]; !exists {
				root[k] = v
			}
		}
	}
	return nil
}

// convertRangeResults recursively converts RangeResult to plain []interface{}
func (t *Transpiler) convertRangeResults(v interface{}) interface{} {
	switch val := v.(type) {
	case RangeResult:
		// Convert RangeResult to plain slice
		result := make([]interface{}, len(val.Values))
		for i, item := range val.Values {
			result[i] = t.convertRangeResults(item)
		}
		return result
	case map[string]interface{}:
		// Recursively convert map values
		result := make(map[string]interface{})
		for k, item := range val {
			result[k] = t.convertRangeResults(item)
		}
		return result
	case []interface{}:
		// Recursively convert array elements
		result := make([]interface{}, len(val))
		for i, item := range val {
			result[i] = t.convertRangeResults(item)
		}
		return result
	default:
		return v
	}
}
